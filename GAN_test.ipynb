{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from torch import optim\n",
        "import os\n",
        "import torchvision.utils as vutils\n",
        "import numpy as np\n",
        "import math\n",
        "import torch\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "GLeBKiOxcKsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mvke2h8mHvU",
        "outputId": "758a56d5-3cba-4f4c-f165-b53417f31388"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "maindir = '/content/drive/MyDrive/GANexp'\n",
        "\n",
        "# Arguments\n",
        "BATCH_SIZE = 256\n",
        "EPOCHS = 100\n",
        "Z_DIM = 5\n",
        "LOAD_MODEL = False\n",
        "CHANNELS = 1\n",
        "DB = 'MNIST' # MNIST | FashionMNIST | USPS\n",
        "\n",
        "if DB == 'MNIST' or DB == 'FashionMNIST':\n",
        "    IMAGE_SIZE = 28\n",
        "elif DB == 'USPS':\n",
        "    IMAGE_SIZE = 16\n",
        "else:\n",
        "    print(\"Incorrect dataset\")\n",
        "    exit(0)\n",
        "\n",
        "if not IMAGE_SIZE % 4 == 0:\n",
        "    print(\"Incompatible Image size\")\n",
        "    exit(0)\n",
        "\n",
        "# Directories for storing model and output samples\n",
        "model_path = os.path.join(maindir+'/model', DB)\n",
        "if not os.path.exists(model_path):\n",
        "    os.makedirs(model_path)\n",
        "samples_path = os.path.join(maindir+'/samples', DB)\n",
        "if not os.path.exists(samples_path):\n",
        "    os.makedirs(samples_path)\n",
        "db_path = os.path.join(maindir+'/data', DB)\n",
        "if not os.path.exists(samples_path):\n",
        "    os.makedirs(samples_path)\n",
        "\n",
        "\n",
        "# Method for storing generated images\n",
        "def generate_imgs(z, epoch=0):\n",
        "    gen.eval()\n",
        "    fake_imgs = gen(z)\n",
        "    fake_imgs_ = vutils.make_grid(fake_imgs, normalize=True, nrow=math.ceil(BATCH_SIZE ** 0.5))\n",
        "    print(fake_imgs_.shape)\n",
        "    vutils.save_image(fake_imgs_, os.path.join(samples_path, 'sample_' + str(epoch) + '.png'))\n",
        "\n",
        "\n",
        "# Data loaders\n",
        "mean = np.array([0.5])\n",
        "std = np.array([0.5])\n",
        "transform = transforms.Compose([transforms.Resize([IMAGE_SIZE, IMAGE_SIZE]),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean, std)])\n",
        "\n",
        "if DB=='MNIST':\n",
        "    dataset = datasets.MNIST(db_path, train=True, download=True, transform=transform)\n",
        "elif DB=='FashionMNIST':\n",
        "    dataset = datasets.FashionMNIST(db_path, train=True, download=True, transform=transform)\n",
        "elif DB=='USPS':\n",
        "    dataset = datasets.USPS(db_path, train=True, download=True, transform=transform)\n",
        "\n",
        "data_loader = torch.utils.data.DataLoader(dataset=dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, drop_last=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "GsAr6mXCcPNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Networks\n",
        "def conv_block(c_in, c_out, k_size=4, stride=2, pad=1, use_bn=True, transpose=False):\n",
        "    module = []\n",
        "    if transpose:\n",
        "        module.append(nn.ConvTranspose2d(c_in, c_out, k_size, stride, pad, bias=not use_bn))\n",
        "    else:\n",
        "        module.append(nn.Conv2d(c_in, c_out, k_size, stride, pad, bias=not use_bn))\n",
        "    if use_bn:\n",
        "        module.append(nn.BatchNorm2d(c_out))\n",
        "    return nn.Sequential(*module)\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, z_dim=10, image_size=28, channels=1, conv_dim=8):\n",
        "        super(Generator, self).__init__()\n",
        "        self.image_size = image_size\n",
        "\n",
        "        self.fc1 = nn.Linear(z_dim,  (self.image_size//4)*(self.image_size//4)*conv_dim*2)\n",
        "        self.tconv2 = conv_block(conv_dim * 2, conv_dim, transpose=True, use_bn=True)\n",
        "        self.tconv3 = conv_block(conv_dim, channels, transpose=True, use_bn=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = x.reshape([x.shape[0], -1, self.image_size//4, self.image_size//4])\n",
        "        x = F.relu(self.tconv2(x))\n",
        "        x = torch.tanh(self.tconv3(x))\n",
        "        return x\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, image_size=28, channels=1, conv_dim=8):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.conv1 = conv_block(channels, conv_dim, use_bn=False)\n",
        "        self.conv2 = conv_block(conv_dim, conv_dim * 2, use_bn=True)\n",
        "        self.fc3 = nn.Linear((image_size//4)*(image_size//4)*conv_dim*2, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        alpha = 0.2\n",
        "        x = F.leaky_relu(self.conv1(x), alpha)\n",
        "        x = F.leaky_relu(self.conv2(x), alpha)\n",
        "        x = x.reshape([x.shape[0], -1])\n",
        "        x = torch.sigmoid(self.fc3(x))\n",
        "        return x.squeeze()\n"
      ],
      "metadata": {
        "id": "yZ-ftQZvcWhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "gen = Generator(z_dim=Z_DIM, image_size=IMAGE_SIZE, channels=CHANNELS)\n",
        "dis = Discriminator(image_size=IMAGE_SIZE, channels=CHANNELS)\n",
        "\n",
        "# Load previous model\n",
        "if LOAD_MODEL:\n",
        "    gen.load_state_dict(torch.load(os.path.join(model_path, 'gen.pkl')))\n",
        "    dis.load_state_dict(torch.load(os.path.join(model_path, 'dis.pkl')))\n",
        "\n",
        "# Model Summary\n",
        "print(\"------------------Generator------------------\")\n",
        "print(gen)\n",
        "print(\"------------------Discriminator------------------\")\n",
        "print(dis)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1FyZIs3cbsB",
        "outputId": "02900635-e2a0-4d7c-f91b-c5184a686c3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------Generator------------------\n",
            "Generator(\n",
            "  (fc1): Linear(in_features=5, out_features=784, bias=True)\n",
            "  (tconv2): Sequential(\n",
            "    (0): ConvTranspose2d(16, 8, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (tconv3): Sequential(\n",
            "    (0): ConvTranspose2d(8, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "  )\n",
            ")\n",
            "------------------Discriminator------------------\n",
            "Discriminator(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(1, 8, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(8, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (fc3): Linear(in_features=784, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Define Optimizers\n",
        "g_opt = optim.Adam(gen.parameters(), lr=0.0002, betas=(0.5, 0.999), weight_decay=2e-5)\n",
        "d_opt = optim.Adam(dis.parameters(), lr=0.0002, betas=(0.5, 0.999), weight_decay=2e-5)\n",
        "\n",
        "# Loss functions\n",
        "loss_fn = nn.BCELoss()\n",
        "\n",
        "# Fix images for viz\n",
        "fixed_z = torch.randn(BATCH_SIZE, Z_DIM)\n",
        "\n",
        "# Labels\n",
        "real_label = torch.ones(BATCH_SIZE)\n",
        "fake_label = torch.zeros(BATCH_SIZE)\n",
        "\n",
        "# GPU Compatibility\n",
        "is_cuda = torch.cuda.is_available()\n",
        "if is_cuda:\n",
        "    gen, dis = gen.cuda(), dis.cuda()\n",
        "    real_label, fake_label = real_label.cuda(), fake_label.cuda()\n",
        "    fixed_z = fixed_z.cuda()\n",
        "\n",
        "total_iters = 0\n",
        "max_iter = len(data_loader)"
      ],
      "metadata": {
        "id": "hTUXS2-1cu4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writerFake = SummaryWriter(f\"logs/fake\")\n",
        "writerReal = SummaryWriter(f\"logs/real\")"
      ],
      "metadata": {
        "id": "yUUfjLqgdNws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnt4RdJfb9r4",
        "outputId": "bc773ae9-56b6-4859-b40b-3adfc4a11731"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/4\titer: 0/234\ttotal_iters: 1\td_loss:0.8276\tg_loss:0.4827\n",
            "Epoch: 1/4\titer: 50/234\ttotal_iters: 51\td_loss:0.3035\tg_loss:1.1681\n",
            "Epoch: 1/4\titer: 100/234\ttotal_iters: 101\td_loss:0.1918\tg_loss:1.5606\n",
            "Epoch: 1/4\titer: 150/234\ttotal_iters: 151\td_loss:0.1326\tg_loss:1.9701\n",
            "Epoch: 1/4\titer: 200/234\ttotal_iters: 201\td_loss:0.0977\tg_loss:2.3606\n",
            "Epoch: 2/4\titer: 0/234\ttotal_iters: 235\td_loss:0.0833\tg_loss:2.5659\n",
            "Epoch: 2/4\titer: 50/234\ttotal_iters: 285\td_loss:0.0665\tg_loss:2.8057\n",
            "Epoch: 2/4\titer: 100/234\ttotal_iters: 335\td_loss:0.0581\tg_loss:2.9872\n",
            "Epoch: 2/4\titer: 150/234\ttotal_iters: 385\td_loss:0.0493\tg_loss:3.1526\n",
            "Epoch: 2/4\titer: 200/234\ttotal_iters: 435\td_loss:0.0396\tg_loss:3.3706\n",
            "torch.Size([3, 482, 482])\n",
            "Epoch: 3/4\titer: 0/234\ttotal_iters: 469\td_loss:0.0392\tg_loss:3.3601\n",
            "Epoch: 3/4\titer: 50/234\ttotal_iters: 519\td_loss:0.0351\tg_loss:3.5017\n",
            "Epoch: 3/4\titer: 100/234\ttotal_iters: 569\td_loss:0.0286\tg_loss:3.745\n",
            "Epoch: 3/4\titer: 150/234\ttotal_iters: 619\td_loss:0.0323\tg_loss:3.6451\n",
            "Epoch: 3/4\titer: 200/234\ttotal_iters: 669\td_loss:0.0615\tg_loss:2.5268\n",
            "Epoch: 4/4\titer: 0/234\ttotal_iters: 703\td_loss:0.0578\tg_loss:2.6786\n",
            "Epoch: 4/4\titer: 50/234\ttotal_iters: 753\td_loss:0.0797\tg_loss:2.9869\n",
            "Epoch: 4/4\titer: 100/234\ttotal_iters: 803\td_loss:0.1108\tg_loss:2.2067\n",
            "Epoch: 4/4\titer: 150/234\ttotal_iters: 853\td_loss:0.0992\tg_loss:2.4592\n",
            "Epoch: 4/4\titer: 200/234\ttotal_iters: 903\td_loss:0.1002\tg_loss:2.7836\n",
            "torch.Size([3, 482, 482])\n",
            "torch.Size([3, 482, 482])\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 4\n",
        "\n",
        "\n",
        "# Training\n",
        "for epoch in range(EPOCHS):\n",
        "    gen.train()\n",
        "    dis.train()\n",
        "\n",
        "    for i, data in enumerate(data_loader):\n",
        "\n",
        "        total_iters += 1\n",
        "\n",
        "        # Loading data\n",
        "        x_real, _ = data\n",
        "        z_fake = torch.randn(BATCH_SIZE, Z_DIM)\n",
        "\n",
        "        if is_cuda:\n",
        "            x_real = x_real.cuda()\n",
        "            z_fake = z_fake.cuda()\n",
        "\n",
        "        # Generate fake data\n",
        "        x_fake = gen(z_fake)\n",
        "\n",
        "        # Train Discriminator\n",
        "        fake_out = dis(x_fake.detach())\n",
        "        real_out = dis(x_real.detach())\n",
        "        d_loss = (loss_fn(fake_out, fake_label) + loss_fn(real_out, real_label)) / 2\n",
        "\n",
        "        d_opt.zero_grad()\n",
        "        d_loss.backward()\n",
        "        d_opt.step()\n",
        "\n",
        "        # Train Generator\n",
        "        fake_out = dis(x_fake)\n",
        "        g_loss = loss_fn(fake_out, real_label)\n",
        "\n",
        "        g_opt.zero_grad()\n",
        "        g_loss.backward()\n",
        "        g_opt.step()\n",
        "\n",
        "        if i % 50 == 0:\n",
        "            print(\"Epoch: \" + str(epoch + 1) + \"/\" + str(EPOCHS)\n",
        "                  + \"\\titer: \" + str(i) + \"/\" + str(max_iter)\n",
        "                  + \"\\ttotal_iters: \" + str(total_iters)\n",
        "                  + \"\\td_loss:\" + str(round(d_loss.item(), 4))\n",
        "                  + \"\\tg_loss:\" + str(round(g_loss.item(), 4))\n",
        "                  )\n",
        "\n",
        "    if (epoch+1) % 2 == 0:\n",
        "        torch.save(gen.state_dict(), os.path.join(model_path, 'gen.pkl'))\n",
        "        torch.save(dis.state_dict(), os.path.join(model_path, 'dis.pkl'))\n",
        "\n",
        "        generate_imgs(fixed_z, epoch=epoch + 1)\n",
        "\n",
        "    # if i % 4 == 0:\n",
        "    #     step = prepareVisualization(epoch,\n",
        "    #                                 i,\n",
        "    #                                 len(data_loader),\n",
        "    #                                 d_loss,\n",
        "    #                                 g_loss,\n",
        "    #                                 writerFake,\n",
        "    #                                 writerReal,\n",
        "    #                                 step)\n",
        "\n",
        "generate_imgs(fixed_z)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_real.shape,BATCH_SIZE,x_fake.shape, z_fake.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBE9VWMahmJD",
        "outputId": "23655f77-255a-4765-d8e0-b111d0652986"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([256, 1, 28, 28]),\n",
              " 256,\n",
              " torch.Size([256, 1, 28, 28]),\n",
              " torch.Size([256, 5]))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def prepareVisualization(epoch,\n",
        "#                          batchIdx,\n",
        "#                          loaderLen,\n",
        "#                          lossD,\n",
        "#                          lossG,\n",
        "#                          writerFake,\n",
        "#                          writerReal,\n",
        "#                          step):\n",
        "#     print(\n",
        "#         f\"Epoch [{epoch}/{Config.numEpochs}] Batch {batchIdx}/{loaderLen} \\\n",
        "#                               Loss DISC: {lossD:.4f}, loss GEN: {lossG:.4f}\"\n",
        "#     )\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#         # Generate noise via Generator\n",
        "#         fake = gen(z_fake).reshape(-1, 1, 28, 28)\n",
        "\n",
        "#         # Get real data\n",
        "#         data = real.reshape(-1, 1, 28, 28)\n",
        "\n",
        "#         # Plot the grid\n",
        "#         imgGridFake = torchvision.utils.make_grid(fake,\n",
        "#                                                   normalize=True)\n",
        "#         imgGridReal = torchvision.utils.make_grid(data,\n",
        "#                                                   normalize=True)\n",
        "\n",
        "#         writerFake.add_image(\"Mnist Fake Images\",\n",
        "#                              imgGridFake,\n",
        "#                              global_step=step)\n",
        "#         writerReal.add_image(\"Mnist Real Images\",\n",
        "#                              imgGridReal,\n",
        "#                              global_step=step)\n",
        "#         # increment step\n",
        "#         step += 1\n",
        "\n",
        "#     return step"
      ],
      "metadata": {
        "id": "WIQGqUEgcxTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F_ODZkIPcgEH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}